{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# import visualization\nimport matplotlib.pyplot as plt\n\n# import machine learning\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import SVR\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, explained_variance_score\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.metrics.pairwise import cosine_similarity","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# load data\nfires = pd.read_csv('../input/forest-fires-data-set/forestfires.csv')\nfires.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.hist(fires.area, bins=20)\nplt.title('Area Distribution')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Long-tailed distribution with small number of samples for high area values."},{"metadata":{"trusted":true},"cell_type":"code","source":"# simple regression model\ndf = pd.get_dummies(fires.drop(columns=['X', 'Y']))\n\nX = df.drop(columns=['area'])\ny = df[['area']]\n\nscaler = StandardScaler()\nX = scaler.fit_transform(X,y)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n\nmodel = LinearRegression()\nmodel.fit(X_train, y_train.values.ravel())\n\ny_pred = model.predict(X_test)\n\n# print out the prediction scores\nprint('RMSE: {}'.format(np.sqrt(mean_squared_error(y_test, y_pred))))\nprint('MAE: {}'.format(mean_absolute_error(y_test, y_pred)))\nprint('R-squared: {}'.format(explained_variance_score(y_test, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(y_pred, y_test)\nplt.plot(y_test, y_test, c = 'orange')\nplt.xlabel('prediction')\nplt.ylabel('true values')\nplt.xlim(0,1000)\nplt.ylim(0,1000)\nplt.title('Predicted vs True values')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We see that the model performs very bad. Ideally the dots should be near the line."},{"metadata":{"trusted":true},"cell_type":"code","source":"# define sigmoid function\n# https://en.wikipedia.org/wiki/Sigmoid_function\ndef sigmoid(x):\n    return 1 / (1 + np.exp(-x))\n\n# plot sigmoid function\nplt.plot(np.linspace(-10, 10, 100), sigmoid(np.linspace(-10, 10, 100)))\nplt.title('Sigmoid Function')\nplt.xlabel('x')\nplt.axhline(y=0, c='black', linestyle=':')\nplt.axvline(x=0, c='black', linestyle=':')\nplt.ylabel('sigmoid(x)')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot the boxplot of area distribution\nplt.boxplot(fires.area, vert=False)\nplt.title('Area Distribution')\nplt.xlabel('area')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# implement relevance function\n# see paper: https://www.researchgate.net/publication/220699419_Utility-Based_Regression\ndef relevance(x):\n    x = np.array(x)\n    return sigmoid(x - 170)\n\n# plot relevance function\nplt.plot(np.linspace(0, 1000, 1000), relevance(np.linspace(0, 1000, 1000)))\nplt.title('Relevance Function')\nplt.xlabel('x')\nplt.axhline(y=0, c='black', linestyle=':')\nplt.axvline(x=0, c='black', linestyle=':')\nplt.ylabel('relevance(x)')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# implement SMOTER\n# see paper: https://core.ac.uk/download/pdf/29202178.pdf\n\ndef get_synth_cases(D, target, o=200, k=3, categorical_col = []):\n    '''\n    Function to generate the new cases.\n    INPUT:\n        D - pd.DataFrame with the initial data\n        target - string name of the target column in the dataset\n        o - oversampling rate\n        k - number of nearest neighbors to use for the generation\n        categorical_col - list of categorical column names\n    OUTPUT:\n        new_cases - pd.DataFrame containing new generated cases\n    '''\n    new_cases = pd.DataFrame(columns = D.columns) # initialize the list of new cases \n    ng = o // 100 # the number of new cases to generate\n    for index, case in D.iterrows():\n        # find k nearest neighbors of the case\n        knn = KNeighborsRegressor(n_neighbors = k+1) # k+1 because the case is the nearest neighbor to itself\n        knn.fit(D.drop(columns = [target]).values, D[[target]])\n        neighbors = knn.kneighbors(case.drop(labels = [target]).values.reshape(1, -1), return_distance=False).reshape(-1)\n        neighbors = np.delete(neighbors, np.where(neighbors == index))\n        for i in range(0, ng):\n            # randomly choose one of the neighbors\n            x = D.iloc[neighbors[np.random.randint(k)]]\n            attr = {}          \n            for a in D.columns:\n                # skip target column\n                if a == target:\n                    continue;\n                if a in categorical_col:\n                    # if categorical then choose randomly one of values\n                    if np.random.randint(2) == 0:\n                        attr[a] = case[a]\n                    else:\n                        attr[a] = x[a]\n                else:\n                    # if continious column\n                    diff = case[a] - x[a]\n                    attr[a] = case[a] + np.random.randint(2) * diff\n            # decide the target column\n            new = np.array(list(attr.values()))\n            d1 = cosine_similarity(new.reshape(1, -1), case.drop(labels = [target]).values.reshape(1, -1))[0][0]\n            d2 = cosine_similarity(new.reshape(1, -1), x.drop(labels = [target]).values.reshape(1, -1))[0][0]\n            attr[target] = (d2 * case[target] + d1 * x[target]) / (d1 + d2)\n            \n            # append the result\n            new_cases = new_cases.append(attr,ignore_index = True)\n                    \n    return new_cases\n\ndef SmoteR(D, target, th = 0.999, o = 200, u = 100, k = 3, categorical_col = []):\n    '''\n    The implementation of SmoteR algorithm:\n    https://core.ac.uk/download/pdf/29202178.pdf\n    INPUT:\n        D - pd.DataFrame - the initial dataset\n        target - the name of the target column in the dataset\n        th - relevance threshold\n        o - oversampling rate\n        u - undersampling rate\n        k - the number of nearest neighbors\n    OUTPUT:\n        new_D - the resulting new dataset\n    '''\n    # median of the target variable\n    y_bar = D[target].median()\n    \n    # find rare cases where target less than median\n    rareL = D[(relevance(D[target]) > th) & (D[target] > y_bar)]\n    # generate rare cases for rareL\n    new_casesL = get_synth_cases(rareL, target, o, k , categorical_col)\n    \n    # find rare cases where target greater than median\n    rareH = D[(relevance(D[target]) > th) & (D[target] < y_bar)]\n    # generate rare cases for rareH\n    new_casesH = get_synth_cases(rareH, target, o, k , categorical_col)\n    \n    new_cases = pd.concat([rareL, rareH], axis=0)\n    \n    # get the number of norm cases\n    nr_norm = int(len(new_cases) * u / 100)\n    \n    # undersample norm cases\n    norm_cases = D[relevance(D[target]) <= th].sample(min(len(D[relevance(D[target]) <= th]), nr_norm))\n    \n    # get the resulting dataset\n    new_D = pd.concat([new_cases, norm_cases], axis=0)\n    \n    return new_D","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.DataFrame(columns=['a', 'b', 'c'])\nfor i in range(5):\n    test = test.append({'a':1, 'b':2, 'c':20.0}, ignore_index = True)\n    test = test.append({'a':1, 'b':2, 'c':500.0}, ignore_index = True)\n    test = test.append({'a':3, 'b':4, 'c':450.0}, ignore_index = True)\n    test = test.append({'a':3, 'b':4, 'c':300.0}, ignore_index = True)\ntest","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"get_synth_cases(test, 'c', 100, 3, categorical_col = ['b'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"SmoteR(test, 'c', th = 0.999, o = 200, u = 300, k = 3, categorical_col = ['b'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}